<h2> Action Recognition Papers </h2>

<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(1).pdf" style="text-decoration:none;">Video Classification with Channel-Separated Convolutional Networks</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(2).pdf" style="text-decoration:none;">Video Action Transformer Network</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(3).pdf" style="text-decoration:none;">Moments in Time Dataset: one million videos for event understanding</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(4).pdf" style="text-decoration:none;">End-to-End, Single-Stream Temporal Action Detection in Untrimmed Videos</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(5).pdf" style="text-decoration:none;">Learning Correspondence from the Cycle-consistency of Time</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(6).pdf" style="text-decoration:none;">SST: Single-Stream Temporal Action Proposals</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(7).pdf" style="text-decoration:none;">YouTube-BoundingBoxes: A Large High-Precision Human-Annotated Data Set for Object Detection in Video</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(8).pdf" style="text-decoration:none;"> Rethinking the Faster R-CNN Architecture for Temporal Action Localization</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(9).pdf" style="text-decoration:none;">Actor and Observer: Joint Modeling of First and Third-Person Videos</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(10).pdf" style="text-decoration:none;">Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(11).pdf" style="text-decoration:none;">Bag-of-Fragments: Selecting and encoding video fragments for event detection and recounting</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(12).pdf" style="text-decoration:none;">AMTnet: Action-Micro-Tube Regression by End-to-end Trainable Deep Architecture</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(13).pdf" style="text-decoration:none;">Learning Video Representations from Correspondence Proposals</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(14).pdf" style="text-decoration:none;">You Only Look Once:
Unified, Real-Time Object Detection</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(15).pdf" style="text-decoration:none;">Temporal Context Network for Activity Localization in Videos</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(16).pdf" style="text-decoration:none;">Unsupervised Action Discovery and Localization in Videos</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(17).pdf" style="text-decoration:none;">SCSampler: Sampling Salient Clips from Video for Efficient Action Recognition</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(18).pdf" style="text-decoration:none;">Long-Term Feature Banks for Detailed Video Understanding</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(19).pdf" style="text-decoration:none;">Spot On: Action Localization from
Pointly-Supervised Proposals</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(20).pdf" style="text-decoration:none;"> Temporal Relational Reasoning in Videos</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(21).pdf" style="text-decoration:none;">Online Real-time Multiple Spatiotemporal Action Localisation and Prediction</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(22).pdf" style="text-decoration:none;">The Visual Centrifuge: Model-Free Layered Video Representations</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(23).pdf" style="text-decoration:none;">Videos as Space-Time Region Graphs</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(24).pdf" style="text-decoration:none;">Human Action Localization
with Sparse Spatial Supervision</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(25).pdf" style="text-decoration:none;">Charades-Ego: A Large-Scale Dataset of Paired Third and First Person Videos</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(26).pdf" style="text-decoration:none;">Incremental Tube Construction for Human Action Detection</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(27).pdf" style="text-decoration:none;">Fast Temporal Activity Proposals for Efficient Detection of Human Actions in Untrimmed Videos</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(28).pdf" style="text-decoration:none;">Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(29).pdf" style="text-decoration:none;">DistInit: Learning Video Representations Without a Single Labeled Video</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(30).pdf" style="text-decoration:none;">Temporal Tessellation: A Unified Approach for Video Analysis</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(31).pdf" style="text-decoration:none;">APT: Action localization Proposals from dense Trajectories</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(32).pdf" style="text-decoration:none;">A Closer Look at Spatiotemporal Convolutions for Action Recognition</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(33).pdf" style="text-decoration:none;">Long-term Temporal Convolutions
for Action Recognition</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(34).pdf" style="text-decoration:none;">Dynamic Image Networks for Action Recognition</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(35).pdf" style="text-decoration:none;">Tube Convolutional Neural Network (T-CNN) for Action Detection in Videos</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(36).pdf" style="text-decoration:none;">Action Recognition with Trajectory-Pooled Deep-Convolutional Descriptors</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(37).pdf" style="text-decoration:none;">Action localization with tubelets from motion</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(38).pdf" style="text-decoration:none;">Learning Activity Progression in LSTMs for Activity Detection and Early Detection</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(39).pdf" style="text-decoration:none;">TORNADO: A Spatio-Temporal Convolutional Regression Network for Video Action Proposal</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(40).pdf" style="text-decoration:none;">Temporal Segment Networks: Towards Good Practices for Deep Action Recognition</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(41).pdf" style="text-decoration:none;">Why Can't I Dance in the Mall?
Learning to Mitigate Scene Bias in Action Recognition</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(42).pdf" style="text-decoration:none;">Long-term Recurrent Convolutional Networks for Visual Recognition and Description</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(43).pdf" style="text-decoration:none;">Collaborative Spatiotemporal Feature Learning for Video Action Recognition</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(44).pdf" style="text-decoration:none;">Deformable Convolutional Networks</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(45).pdf" style="text-decoration:none;">Action Detection by Implicit Intentional Motion Clustering</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(46).pdf" style="text-decoration:none;">Action Localization in Videos through ContextWalk</a></li> 
                             
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(47).pdf" style="text-decoration:none;">Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(48).pdf" style="text-decoration:none;">PathTrack: Fast Trajectory Annotation with Path Supervision</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(49).pdf" style="text-decoration:none;">What and How Well You Performed? A Multitask Learning Approach to Action Quality Assessment</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(50).pdf" style="text-decoration:none;">Spatial-Aware Object Embeddings for Zero-Shot Localization and Classification of Actions</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(51).pdf" style="text-decoration:none;">The Design and Implementation of ViPER</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(52).pdf" style="text-decoration:none;">End-to-end Learning of Action Detection from Frame Glimpses in Videos</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(53).pdf" style="text-decoration:none;">Hidden Two-Stream Convolutional Networks for Action Recognition</a></li>
 
<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(54).pdf" style="text-decoration:none;">Temporal Convolutional Networks
for Action Segmentation and Detection </a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(55).pdf" style="text-decoration:none;">Convolutional Two-Stream Network Fusion for Video Action Recognition</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(56).pdf" style="text-decoration:none;">Weakly Supervised Action Localization by Sparse Temporal Pooling Network</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(57).pdf" style="text-decoration:none;">Neural Graph Matching Networks for Fewshot 3D Action Recognition </a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(58).pdf" style="text-decoration:none;">Real-time Action Recognition with Enhanced Motion Vector CNNs</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(59).pdf" style="text-decoration:none;">CortexNet: a Generic Network Family for Robust Visual Temporal Representations</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(60).pdf" style="text-decoration:none;">Temporal Action Detection with Structured Segment Networks</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(61).pdf" style="text-decoration:none;">Describing Videos by Exploiting Temporal Structure</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(62).pdf" style="text-decoration:none;">Large-scale weakly-supervised pre-training for video action recognition</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(63).pdf" style="text-decoration:none;">Learning to track for spatio-temporal action localization</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(64).pdf" style="text-decoration:none;">A Better Baseline for AVA</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(65).pdf" style="text-decoration:none;">Spatio-Temporal Object Detection Proposals</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(66).pdf" style="text-decoration:none;">Fast Action Proposals for Human Action Detection and Search</a></li> 
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(67).pdf" style="text-decoration:none;">Temporal Deformable Residual Networks for Action Segmentation in Videos</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(68).pdf" style="text-decoration:none;">Representation Flow for Action Recognition</a></li> 
 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(69).pdf" style="text-decoration:none;">Fully Context-Aware Video Prediction</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(70).pdf" style="text-decoration:none;">Timeception for Complex Action Recognition</a></li> 
  
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(71).pdf" style="text-decoration:none;">Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?</a></li>
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(72).pdf" style="text-decoration:none;">Part-based Graph Convolutional Network for Action Recognition</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Action-Recognition-Papers/blob/master/fre(73).pdf" style="text-decoration:none;">Temporal 3D ConvNets using Temporal Transition Layer</a></li>
  </ul>
  
  
